// voice_ai_callcenter_server/server.js

require('dotenv').config();
const express = require('express');
const bodyParser = require('body-parser');
const axios = require('axios');
const { v4: uuidv4 } = require('uuid');
const fs = require('fs');
const path = require('path');
const http = require('http');
const WebSocket = require('ws');

const app = express();
const PORT = process.env.PORT || 3000;

app.use(bodyParser.urlencoded({ extended: true }));
app.use(bodyParser.json());

// Endpoint Twilio Voice Webhook
app.post('/voice', (req, res) => {
  const response = `<?xml version="1.0" encoding="UTF-8"?>
    <Response>
      <Start>
        <Stream url=\"wss://${process.env.RENDER_EXTERNAL_HOSTNAME}/stream\" />
      </Start>
      <Say language=\"pl-PL\" voice=\"Polly.Agnieszka\">Witaj w Moja Szwajcaria. ProszÄ™ powiedzieÄ‡, w czym moÅ¼emy pomÃ³c.</Say>
      <Pause length=\"60\"/>
    </Response>`;

  res.type('text/xml');
  res.send(response);
});

// Twilio Media Stream WebSocket
const server = http.createServer(app);
const wss = new WebSocket.Server({ server, path: '/stream' });

wss.on('connection', (ws) => {
  console.log('ğŸ§ Nowe poÅ‚Ä…czenie gÅ‚osowe z Twilio');
  let audioBuffer = [];

  ws.on('message', async (msg) => {
    const message = JSON.parse(msg);
    if (message.event === 'media') {
      const audioData = Buffer.from(message.media.payload, 'base64');
      audioBuffer.push(audioData);
    }
    if (message.event === 'stop') {
      console.log('ğŸ›‘ Koniec rozmowy â€“ analizujÄ™...');

      const fullAudio = Buffer.concat(audioBuffer);
      const transcription = await transcribeAudio(fullAudio);
      const gptResponse = await askGPT(transcription);
      const audioUrl = await synthesizeVoice(gptResponse);

      console.log('ğŸ¤ AI odpowiedziaÅ‚o:', gptResponse);
      // tu moÅ¼esz dodaÄ‡ wysyÅ‚anie odpowiedzi gÅ‚osowej do klienta
    }
  });
});

async function transcribeAudio(buffer) {
  try {
    const response = await axios.post('https://api.openai.com/v1/audio/transcriptions',
      buffer,
      {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'audio/mpeg'
        },
        params: { model: 'whisper-1' }
      }
    );
    return response.data.text;
  } catch (err) {
    console.error('BÅ‚Ä…d transkrypcji:', err.response?.data || err.message);
    return '';
  }
}

async function askGPT(prompt) {
  try {
    const response = await axios.post('https://api.openai.com/v1/chat/completions', {
      model: 'gpt-4',
      messages: [
        { role: 'system', content: 'JesteÅ› doradcÄ… Moja Szwajcaria, prowadÅº rozmowÄ™ naturalnie i sprzedaÅ¼owo.' },
        { role: 'user', content: prompt }
      ]
    }, {
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      }
    });
    return response.data.choices[0].message.content;
  } catch (err) {
    console.error('BÅ‚Ä…d GPT:', err.response?.data || err.message);
    return 'Przepraszam, nie zrozumiaÅ‚em.';
  }
}

async function synthesizeVoice(text) {
  // Tu moÅ¼esz dodaÄ‡ Google TTS lub ElevenLabs
  console.log('ğŸ”Š [TTS] Symulacja mowy:', text);
  return null;
}

server.listen(PORT, () => {
  console.log(`Voice AI Call Center server listening on port ${PORT}`);
});
